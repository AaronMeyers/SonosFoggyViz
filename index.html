<!DOCTYPE html>
<html lang="en">
	<head>
		<title>SONOS FOGGY VIZ</title>
		<meta charset="utf-8">
		<style>
			body {
				margin: 0px;
				background-color: #000000;
				overflow: hidden;
			}

			label, input {
				cursor: pointer;
			}
		</style>
	</head>
	<body>

		<!-- VARIOUS LIBS -->
		<script src="./js/fft.js"></script>
		<script src="./js/beatdetektor.js"></script>
		<script src="./js/dat.gui.min.js"></script>
		<!-- THREE.JS STUFF -->
		<script src="../three.js/build/three.min.js"></script>
		<script src="../three.js/examples/js/shaders/CopyShader.js"></script>
		<script src="../three.js/examples/js/shaders/RGBShiftShader.js"></script>
		<script src="../three.js/examples/js/shaders/EdgeShader.js"></script>
		<script src="../three.js/examples/js/shaders/EdgeShader2.js"></script>
		<script src="../three.js/examples/js/postprocessing/EffectComposer.js"></script>
		<script src="../three.js/examples/js/postprocessing/RenderPass.js"></script>
		<script src="../three.js/examples/js/postprocessing/MaskPass.js"></script>
		<script src="../three.js/examples/js/postprocessing/ShaderPass.js"></script>
		<!-- MODULES -->
		<script src="./js/modules/test_module.js"></script>
		<script src="./js/modules/empty_module.js"></script>

		<script>
			var gui;

			var audio = {
				element: null,
				bufferSize: 0,
				signal: null,
				channels: 0,
				rate: 0,
				fft: null,
				bd: null,
				kick_det: null,
				vu: null,
				testThing: 0,
				testBool: false,
			};

			var audioContext;
			var audioSource;
			var audioData;

			var m_BeatTimer = 0;
			var m_BeatCounter = 0;
			var clearClr = [0, 0, 1];

			var lastKick = new Date().getTime();
			var kickThreshold = 500; // minimum threshold between kicks in ms
			var displayFFT = false;

			var camera, scene, renderer, composer;

			// modules
			var modules = {};
			var module = '';
			var activeModule;

			var postProcessing = {
				rgbShift: false,
				edgeEffect: false,
				edgeEffect2: false
			};
			var rgbShiftEffect, edgeEffect, edgeEffect2;

			init();
			animate();

			function init() {

				initAudio();

				renderer = new THREE.WebGLRenderer();
				renderer.setSize( window.innerWidth, window.innerHeight );
				document.body.appendChild( renderer.domElement );

				scene = new THREE.Scene();

				camera = new THREE.OrthographicCamera( 0, window.innerWidth, window.innerHeight / 2, window.innerHeight / - 2, - 500, 1000 );
				camera.position.z = 400;

				// initRects();

				initPostProcessing();

				initGUI();

				initModules();



				window.addEventListener( 'resize', onWindowResize, false );
			}

			function initGUI() {

				gui = new dat.GUI({
					height: 1000
				});

				gui.add( this, 'module', ['testModule', 'emptyModule'] ).onChange( function( value ) {
					activeModule.off();
					activeModule = modules[value];
					activeModule.on();
				});

				// var audioFolder = gui.addFolder( 'Audio' );
				// audioFolder.add( audio, 'testThing' );
				// audioFolder.add( audio, 'testBool' );
				// audioFolder.open();

				var ppFolder = gui.addFolder( 'Post Processing' );
				ppFolder.add( postProcessing, 'rgbShift' ).onChange( function( value ) {
					rgbShiftEffect.enabled = value;
				});
				ppFolder.add( postProcessing, 'edgeEffect' ).onChange( function( value ) {
					edgeEffect.enabled = value;
				});
				ppFolder.add( postProcessing, 'edgeEffect2' ).onChange( function( value ) {
					edgeEffect2.enabled = value;
				});
			}

			function initModules() {
				modules.testModule = new TestModule( audio, scene, gui.addFolder( 'Test Module' ) );
				modules.emptyModule = new EmptyModule( audio, scene, gui.addFolder( 'Empty Module' ) );

				activeModule = modules.testModule;
				activeModule.on();
			}

			function initPostProcessing() {
				composer = new THREE.EffectComposer( renderer );
				composer.addPass( new THREE.RenderPass( scene, camera ) );

				rgbShiftEffect = new THREE.ShaderPass( THREE.RGBShiftShader );
				rgbShiftEffect.uniforms[ 'amount' ].value = 0.0015;
				rgbShiftEffect.enabled = postProcessing.rgbShift;
				composer.addPass( rgbShiftEffect );

				edgeEffect = new THREE.ShaderPass( THREE.EdgeShader );
				edgeEffect.uniforms[ 'aspect' ].value.x = window.innerWidth;
				edgeEffect.uniforms[ 'aspect' ].value.y = window.innerHeight;
				edgeEffect.enabled = postProcessing.edgeEffect;
				composer.addPass( edgeEffect );

				edgeEffect2 = new THREE.ShaderPass( THREE.EdgeShader2 );
				edgeEffect2.uniforms[ 'aspect' ].value.x = window.innerWidth;
				edgeEffect2.uniforms[ 'aspect' ].value.y = window.innerHeight;
				edgeEffect2.enabled = postProcessing.edgeEffect2;
				composer.addPass( edgeEffect2 );

				var effect = new THREE.ShaderPass( THREE.CopyShader);
				effect.renderToScreen = true;
				composer.addPass( effect );
			}

			function initAudio() {
				// create the audio context
				if (!audioContext) audioContext = new webkitAudioContext();
				// set some audio variables
				audio.bufferSize = 1024;
				audio.channels = 1;
				audio.rate = audioContext.sampleRate;
				// create a node so we can get callbacks
				audioData = audioContext.createJavaScriptNode(audio.bufferSize, 2, 1);
				// set the callback function
				audioData.onaudioprocess = doWebkitAudio;
				// request permission to get the users mic/input/whatever
				navigator.webkitGetUserMedia( {audio:true}, function( stream ) {
					// create an audio source from the stream
					audioSource = audioContext.createMediaStreamSource( stream );
					// connect it to our node
					audioSource.connect( audioData );
					// route that to the audio context and we're good to go
					audioData.connect( audioContext.destination );
					// set up our FFT analyzer
					audio.fft = new FFT(audio.bufferSize, audio.rate);
				});
				// initialize beat detector and modules
				audio.bd = new BeatDetektor();
				audio.kick_det = new BeatDetektor.modules.vis.BassKick();
				audio.vu = new BeatDetektor.modules.vis.VU();
			}

			function doWebkitAudio() {
				if ( !audio.fft ) {
					return;
				}

				var signalLeft = event.inputBuffer.getChannelData(0);
				var signalRight = event.inputBuffer.getChannelData(1);

				if (!audio.signal) {
					audio.signal = new Float32Array(signalLeft.length);
				}
				for (var i = 0, fbl = audio.bufferSize; i < fbl; i++) {
					audio.signal[i] = signalLeft[i] + signalRight[i] / 2;
				}

				audio.fft.forward(audio.signal);
				audio.bd.process(event.timeStamp / 1000, audio.fft.spectrum);

				if (audio.bd.win_bpm_int_lo) {
					m_BeatTimer += audio.bd.last_update;

					if (m_BeatTimer > (60.0 / audio.bd.win_bpm_int_lo)) {
						m_BeatTimer -= (60.0 / audio.bd.win_bpm_int_lo);
						clearClr[0] = 0.5 + Math.random() / 2;
						clearClr[1] = 0.5 + Math.random() / 2;
						clearClr[2] = 0.5 + Math.random() / 2;
						m_BeatCounter++;
					}
				}

				audio.kick_det.process( audio.bd );

				if ( audio.kick_det.isKick() ) {
					var diff = event.timeStamp - lastKick;
					if ( diff > kickThreshold ) {
						// A KICK HAPPENED HERE
						lastKick = event.timeStamp;
					}

				}

                audio.vu.process(audio.bd, event.timeStamp / 1000);
			}

			function onWindowResize() {
				camera.left = 0;
				camera.right = window.innerWidth;
				camera.top = window.innerHeight / 2;
				camera.bottom = window.innerHeight / - 2;

				camera.updateProjectionMatrix();

				renderer.setSize( window.innerWidth, window.innerHeight );

				edgeEffect.uniforms[ 'aspect' ].value.x = window.innerWidth;
				edgeEffect.uniforms[ 'aspect' ].value.y = window.innerHeight;
				edgeEffect2.uniforms[ 'aspect' ].value.x = window.innerWidth;
				edgeEffect2.uniforms[ 'aspect' ].value.y = window.innerHeight;
			}

			function animate() {

				requestAnimationFrame( animate );

				if ( activeModule )
					activeModule.update();

				composer.render();
				// renderer.render(scene, camera);

			}

		</script>
	</body>
</html>
